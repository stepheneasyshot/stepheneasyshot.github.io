---
layout: post
description: > 
  本文梳理了当下最流行的几种AI大模型的原理概念
image: 
  path: /assets/img/blog/blogs_ai_cover.png
  srcset: 
    1920w: /assets/img/blog/blogs_ai_cover.png
    960w:  /assets/img/blog/blogs_ai_cover.png
    480w:  /assets/img/blog/blogs_ai_cover.png
accent_image: /assets/img/blog/blogs_ai_cover.png
excerpt_separator: <!--more-->
sitemap: false
---
# AI大模型原理概念调研
## GPT篇
GPT，generative pre-trained transformer，即生成式预训练转换器，是一种大型语言模型 (LLM，large language model)，利用深度学习生成类似人类的文本。神经网络在包含文本和代码的海量数据集上进行训练，使其能够理解并生成连贯且与上下文相关的响应。作为生成式人工智能领域的关键组成部分，GPT 突破了人工智能的极限，使机器能够生成具有创造性和人类品质的内容。

### GPT 如何工作？
GPT 模型是一种复杂的人工神经元网络，分层组织以深入处理信息，就像人类大脑一样。它的架构被称为 **transformer** ，这是谷歌研究人员于 2017 年发明并开源的一种神经网络设计。transformer 允许它 **同时分析整个句子，而不是按顺序分析，从而掌握单词之间的关系** ，而不管单词之间的距离有多远。 

这种能力源自“自我注意力”，这种机制让模型能够 **权衡每个单词相对于所有其他单词的重要性** ，模仿人类如何关注句子的不同部分以获取上下文。  

训练这个模型需要输入大量的文本数据（书籍、文章、代码、在线对话），让模型接触人类语言的范围和细微差别。通过反复接触和“反向传播”过程，模型会从预测误差中学习，从而改进其语言的内部表征，变得非常善于理解和生成人类质量的文本。

### GPT的应用？
#### 内容创作
GPT 模型可以帮助为网站、博客、社交媒体等创建高质量的内容。对于需要定期创建引人入胜且信息丰富的内容的企业和个人来说，这可能是一种有价值的工具。

一个例子是使用 GPT 模型根据提供给模型的特定提示和信息来起草自定义社交媒体帖子或撰写产品描述。这可以帮助腾出时间来完成其他任务。

#### 客户服务
这些模型可用于支持聊天机器人和虚拟助手，以提供客户支持、回答问题和解决问题。这可以帮助企业提高客户满意度并降低支持成本。

想象一下，无论白天还是晚上，您都可以随时获得即时客户服务支持，而无需等待或浏览复杂的电话菜单。这就是人工智能客户服务的潜力。

#### 聊天机器人
除了客服之外，聊天机器人还可以被更广泛的受众用来回答问题，甚至进行随意的交谈。随着 GPT 技术的不断发展，未来有望出现更加复杂、更像人类的聊天机器人。

#### 代码生成
GPT 技术有可能彻底改变开发人员的工作方式。它可用于协助计算机代码生成，这对于希望自动化任务或加快开发过程的开发人员来说是一个有价值的工具。

这可以让开发人员腾出时间专注于更复杂、更有创意的任务。想象一下，在未来，即使是那些编码经验有限的人也可以借助人工智能代码生成工具将自己的想法变成现实。

#### 教育
GPT 有可能通过提供针对每个学生需求的个性化学习体验来改变教育。它可以提供量身定制的反馈、练习题、互动模块、学习计划、虚拟导师和语言支持。这种人工智能的整合可以为所有学生创造一个包容、引人入胜且有效的学习环境。

### GPT 为何重要？
GPT 的意义在于它能够通过语言弥合人与机器之间的鸿沟。它能够熟练地理解和生成类似人类的文本，为沟通、自动化和创意表达开辟了新的可能性。

此外，GPT 对各个领域和任务的适应性使其成为一种变革性技术，有可能彻底改变各种各样的行业。 

### GPT 培训
训练 GPT 模型是一个计算密集型的过程，需要输入大量文本数据并采用自我监督学习方法。该模型不依赖于明确标记的数据；相反，它通过识别数据本身的模式和关系来学习。

训练过程通常涉及以下步骤：

* 数据准备：第一步是收集并准备大量文本和代码数据集。该数据集经过精心策划，尽可能多样化和具有代表性，涵盖广泛的主题、写作风格和语言。
* 标记化：然后将文本数据划分为称为“标记”的较小单元。这些可以是单个单词、单词的一部分，甚至是字符，具体取决于特定的 GPT 模型和所需的粒度级别。
* 模型初始化： GPT 模型使用随机参数进行初始化。这些参数将在训练过程中随着模型从数据中学习而进行调整。
* 自监督学习：然后向模型输入标记化的文本数据，并让其预测序列中的下一个标记。例如，给定输入“The cat sat on the”，模型可能会预测“mat”。
* 反向传播和优化：将模型的预测与训练数据中的实际下一个标记进行比较，并使用它们之间的差异来计算“损失”值。此损失表示模型的预测与事实的偏差。然后，模型使用反向传播来调整其内部参数以最大限度地减少此损失。这种预测、损失计算和参数调整的迭代过程会持续许多个时期，模型会逐渐提高其准确预测序列中下一个标记的能力。

训练数据集的大小、GPT 模型的复杂性以及可用的计算资源在确定训练所需的时间和资源方面都起着至关重要的作用。训练大型 GPT 模型可能需要大量时间，需要专门的硬件和大量的能源消耗。

## Grok篇
Grok 是埃隆·马斯克的公司 **xAI** 开发的一款对话式人工智能聊天机器人。Grok 可以通过社交媒体平台 X 访问实时信息，据说可以回答大多数其他人工智能系统通常拒绝回答的“棘手”问题。与独立的 AI 工具不同，Grok 位于 X（前身为 Twitter）内。要访问它，用户必须 **登录 X 并购买 Grok 订阅** 。这种整合符合马斯克将社交媒体平台转变为“万能应用”的愿景，Grok 等工具可以补充平台的服务生态系统。

Grok 本质上是马斯克对 ChatGPT 的回应，后者的创造者 (OpenAI) 是马斯克于 2015 年共同创立的，但在 与现任首席执行官 Sam Altman发生权力斗争后于 2018 年离开。此后，马斯克谴责 ChatGPT 过于 **左倾和危险** 。据马斯克称，xAI 旨在成为 OpenAI 的直接竞争对手，其 Grok 聊天机器人不仅是 ChatGPT 的“反觉醒”对手，而且还展示了更大的 生成 AI领域的新可能性。

Grok-1 是 Grok 所依赖的大型语言模型，它使用基于软件管理系统 Kubernetes、机器学习框架 JAX 和编码语言 Rust的定制技术栈进行训练，所有这些都帮助 xAI 比其他聊天机器人更快、更高效地开发 Grok。 

与所有 LLM 一样，Grok-1 也接受了从互联网上抓取的大量文本数据的训练，这些数据包括从维基百科文章到科学论文的所有内容。但 Grok 的不同之处在于它 **可以直接访问 X 上的帖子** 。据该公司称，这使得 Grok 能够“实时了解世界”，这让它“比其他模型具有巨大优势”。

### 独特的两种模式
Grok 提供两种交互方式：“趣味模式”和“常规模式”。默认情况下，Grok 以“趣味模式”运行，这会导致聊天机器人呈现出更前卫或更幽默的个性，有时甚至会产生与事实不符的回答。“常规模式”通常会提供更准确的答案，但与所有 AI 聊天机器人一样，xAI 表示它仍然可能生成 虚假或矛盾的信息。

### 交互范围更宽泛
Grok 可以起草电子邮件、调试代码、产生想法等等，而且全部以 流畅的类人语言完成。它只需接收输入（如命令或问题），应用训练数据中的知识，然后使用复杂的 神经网络生成相关的文本输出。

虽然它的使用方式与其他 AI 聊天机器人相同，事实上，Grok 愿意回答大多数其他聊天机器人会拒绝的问题，无论这些问题有多么 禁忌或具有潜在危害。它的设计更像是一个“好玩又有趣的聊天机器人，你可以用它进行更另类或尖刻的对话。”

从用户界面的角度来看，Grok 还可以同时处理多个查询，用户可以在这些答案之间切换，正如 xAI 联合创始人 Toby Pohlen 在视频演示中展示的那样。代码生成可以直接在Visual Studio Code 编辑器中打开，而文本响应可以保存在 markdown 编辑器中以供日后使用。

### 同GPT的对比
#### Grok更具有实时性
Grok 可以直接实时访问 X 上的帖子，而 ChatGPT 的免费版本只知道截至 2022 年 1 月的信息，付费版本只知道截至 2023 年 4 月的信息。这意味着 Grok 可以参与有关最近事件的对话，例如以色列-哈马斯战争或 2024 年超级碗。事实上，根据提出的问题，Grok 实际上会显示它所引用的 X 上的真实帖子，以表明其观点来自何处。

然而，Vice 的一项调查发现，**Grok 倾向于散布有关时事的不准确信息，并让人们相信未经证实的阴谋论**

#### Grok更不具有政治正确性
用马斯克的话来说，Grok 是“最大限度寻求真相”和“基于事实”的，这意味着它毫无歉意并且在交流时不考虑政治正确性。  

AI 创建了一个不太政治正确的聊天机器人，而此时大多数其他大型人工智能公司都在努力让自己的聊天机器人更加政治化。OpenAI 声称，其新推出的 GPT-4 LLM（为 ChatGPT 的付费版本提供支持）对“不允许的内容”请求的响应可能性降低了 82%，其中包括“仇恨、骚扰”和“暴力”的材料。而 Anthropic 的 Claude聊天机器人是使用宪法人工智能进行训练的，这 有助于降低其产生有毒、危险或不道德反应的可能性。

## Gemini篇
Google Gemini（原名 Bard）是 **Google** 设计的一款人工智能 (AI)聊天机器人工具，使用自然语言处理 ( NLP ) 和机器学习模拟人类对话。除了补充 Google 搜索外，Gemini 还可以集成到网站、消息平台或应用程序中，为用户问题提供逼真的自然语言回答。

Google Gemini 是一系列多模式 AI大型语言模型 ( LLM )，具有语言、音频、代码和视频理解能力。

2024 年 12 月 11 日，谷歌发布了其 LLM 的更新版本，其中包含 **Gemini 2.0 Flash** ，这是 Google AI Studio 和 Vertex AI Gemini 应用程序编程接口 (API) 中集成的实验版本。

### 特性
Gemini 集成了 NLP 功能，可提供理解和处理语言的能力。Gemini 还用于理解输入查询和数据。它能够理解和识别图像，使其能够解析复杂的视觉效果，例如图表和数字，而无需外部光学字符识别 ( OCR )。它还具有广泛的多语言功能，可用于翻译任务和跨不同语言的功能。

与谷歌之前的 AI 模型不同，Gemini 本身就是多模态的，这意味着它对跨多种数据类型的数据集进行端到端训练。作为多模态模型，Gemini 具有跨模态推理能力。这意味着 Gemini 可以对一系列不同的输入数据类型进行推理，包括音频、图像和文本。例如，Gemini 可以理解手写笔记、图形和图表来解决复杂问题。Gemini 架构支持直接将文本、图像、音频波形和视频帧作为交错序列提取。

### Google Gemini 如何运作？
Google Gemini 首先在海量数据上进行训练。训练后，该模型使用多种神经网络技术来理解内容、回答问题、生成文本并产生输出。

具体来说，Gemini LLM 使用基于 **Transformer** 模型的神经网络架构。Gemini 架构已得到增强，可以处理不同数据类型（包括文本、音频和视频）的长上下文序列。Google DeepMind 在 Transformer 解码器中使用高效的 **注意力机制** ，帮助模型处理跨越不同模态的长上下文。

Gemini 模型已在 Google DeepMind 的多种多模式和多语言文本、图像、音频和视频数据集上进行了训练，并使用高级数据过滤来优化训练。随着不同的 Gemini 模型被部署以支持特定的 Google 服务，有一个有针对性的微调过程可用于进一步优化用例的模型。在训练和推理阶段，Gemini 受益于使用 Google 最新的张量处理单元芯片 Trillium（第六代 Google Cloud TPU）。与 TPU v5 相比，Trillium TPU 提供了更高的性能、更低的延迟和更低的成本。它们也比以前的版本更节能。

### Gemini 可以执行的任务
Google Gemini 可以实用地应用于完成各种任务。
LLM 面临的一个关键挑战是存在偏见和潜在有害内容的风险。据 Google 称，Gemini 针对偏见和毒性等风险进行了广泛的安全测试和缓解，以帮助提供一定程度的 LLM 安全性。为了进一步确保 Gemini 正常运行，这些模型根据语言、图像、音频、视频和代码领域的学术基准进行了测试。Google 向公众保证，它遵守一系列 AI 原则。

谷歌在 2023 年 12 月 6 日发布时表示，Gemini 将包含一系列不同大小的模型，每种模型都针对特定的用例和部署环境而设计。

* Ultra 模型是最高端的，专为高度复杂的任务而设计。
* Pro 模型专为大规模性能和部署而设计。截至 2023 年 12 月 13 日，谷歌已在 Google Cloud Vertex AI 和 Google AI Studio 中启用了对 Gemini Pro 的访问。对于代码，Gemini 的一个版本用于支持 Google AlphaCode 2 生成式 AI 编码技术。
* Nano 模型针对的是设备上的使用案例。Gemini Nano 有两个不同版本：Nano-1 模型有 18 亿个参数，而 Nano-2 有 32.5 亿个参数。Nano 被嵌入的地方包括 Google Pixel 9 智能手机。

### Gemini 有何用途？用例和应用
Google Gemini 模型有多种用途，包括文本、图像、音频和视频理解。Gemini 的多模态特性还使这些不同类型的输入能够组合起来生成输出。

* 文本摘要。Gemini模型可以从不同类型的数据中总结内容。
* 文本生成。Gemini可以根据用户提示生成文本。该文本也可以由问答类型的聊天机器人界面驱动。
* 文本翻译。Gemini模型具有广泛的多语言功能，可以翻译和理解 100 多种语言。
* 图像理解。Gemini无需外部 OCR 工具即可解析复杂的视觉效果，例如图表、图形和图解。它可用于图像字幕和视觉问答功能。
* 音频处理。Gemini支持100 多种语言的语音识别和音频翻译任务。
* 视频理解。Gemini可以处理和理解视频片段帧，以回答问题并生成描述。
* 多模态推理。Gemini的一个主要优势是它使用多模态 AI 推理，可以混合不同类型的数据以提示生成输出。
* 代码分析和生成。Gemini可以理解、解释和生成流行编程语言的代码，包括 Python、Java、C++ 和 Go。

#### 应用
Google 开发了 Gemini 作为基础模型，以便广泛集成到各种 Google 服务中。开发人员还可以使用它来构建自己的应用程序。使用 Gemini 的应用程序包括：

* AlphaCode 2. Google DeepMind 的 AlphaCode 2 代码生成工具使用了 Gemini Pro 的定制版本。
* Google Pixel。谷歌打造的 Pixel 8 Pro 智能手机是首款运行 Gemini Nano 的设备。Gemini 为现有 Google 应用中的新功能提供支持，例如 Recorder 中的摘要功能和 Gboard 中用于消息应用的智能回复功能。
* Android。Pixel 8 Pro 是首款受益于 Gemini 的 Android 智能手机。Android 开发人员可以通过 Android 操作系统的 AICore 系统功能使用 Gemini Nano 进行构建。
* Vertex AI。Google Cloud 的 Vertex AI 服务提供了开发人员可以用来构建应用程序的基础模型，同时还提供对 Gemini Pro 的访问权限。
* Google AI Studio。开发人员可以使用基于 Web 的 Google AI Studio 工具通过 Gemini 构建原型和应用程序。
* 搜索。谷歌已尝试在其AI 概览中使用 Gemini来减少延迟并提高质量。

### Gemini的局限性
一些限制可能会导致潜在最终用户犹豫。这些限制包括：

* 训练数据。与所有 AI 聊天机器人一样，Gemini 必须学会给出正确的答案。要做到这一点，模型必须接受正确信息训练，这些信息不能不准确或误导。然而，它们还必须能够识别错误或误导性的信息。
* 偏见和潜在危害。人工智能训练是一个永无止境的、计算密集型的过程，因为总有新的信息需要学习。谷歌声称，在所有 Gemini 模型中，它都遵循了负责任的开发实践，包括广泛的评估，以帮助限制偏见和潜在危害的风险。
* 原创性和创造性。Gemini制作的内容的原创性和创造性是有限的。免费版本尤其如此，它在处理复杂的提示、多个步骤和细微差别以及产生足够的输出方面存在困难。免费版本基于 Gemini Pro LLM，其功能更有限；该平台的付费版本提供更高级的功能。

**值得担心的事情**

Gemini 的一个担忧在于它可能会向用户提供有偏见或虚假的信息。输入 Gemini 的训练数据中存在的任何偏见都可能导致问题。例如，与所有先进的人工智能软件一样，如果训练数据排除了特定人群中的某些群体，则会导致输出结果出现偏差。

Gemini 倾向于产生幻觉和其他虚构内容，并将它们当作真实内容传递给用户，这也是一个令人担忧的问题。自ChatGPT 诞生以来，这一直是其响应面临的最大风险之一，其他高级 AI 工具也是如此。此外，由于 Gemini 并不总是理解上下文，因此其响应可能与用户提供的提示和查询不相关。

