---
layout: post
description: > 
  本文介绍了文本模型之外的多模态AI模型如何处理数据的
image: 
  path: /assets/img/blog/blogs_ai_multimodelai_cover.png
  srcset: 
    1920w: /assets/img/blog/blogs_ai_multimodelai_cover.png
    960w:  /assets/img/blog/blogs_ai_multimodelai_cover.png
    480w:  /assets/img/blog/blogs_ai_multimodelai_cover.png
accent_image: /assets/img/blog/blogs_ai_multimodelai_cover.png
excerpt_separator: <!--more-->
sitemap: false
---
# 【AI】多模态模型的多样化数据处理
经过前面若干篇的学习，我了解到LLM是如何处理输入文本，一轮一轮地进行前向推理，最后输出结果反馈的。

那多模态的AI模型，又是如何处理一帧一帧的图像，或者音频数据呢？现对这些不同于文本的数据处理进行一段学习总结。

## 图像数据
第一步类似于文本模型，首先要理解输入内容物是什么东西。在将图片信息与其他模态（如文本）进行融合之前，模型需要将原始像素数据转换为**有意义的、可供计算的向量表示**，这称为特征提取。

### 数据特征提取
一般通过 **卷积神经网络 (CNN)**，尤其是像 ResNet、VGG 或 ViT (Vision Transformer) 这样的模型架构。
* **CNN 的作用：** CNN 通过多层**卷积**操作，从图片中自动学习和提取层级特征。浅层提取边缘、纹理等基础特征；深层提取鼻子、眼睛、汽车等高层语义特征。
* **Vision Transformer (ViT) 的作用：** ViT 不使用卷积，而是将图像分割成许多小块（称为 **Patch**），然后使用 **Transformer 的自注意力机制**来捕捉这些小块之间的关系，这与处理文本的方式相似，有助于模态间的对齐。

提取器最终输出一个**图像嵌入向量 (Image Embedding)**，它是一个高维向量，浓缩了整张图片或图片中关键区域的语义信息。

### 卷积神经网络是如何处理一张图片的
**卷积神经网络 (CNN)** 是实现图像识别的基石。

与我们人类看到一张图片时能迅速识别出整体不同，计算机看到的是一个巨大的数字矩阵（即像素值）。CNN 的设计思想就是模仿人类视觉皮层的工作方式，通过一系列巧妙的数学操作，逐步从原始像素中提取出有意义的、越来越抽象的特征。

一张彩色图片被表示为一个三维矩阵（H × W × C）。
* H（高度）和 W（宽度）是图片的尺寸。
* C 是**通道数 (Channels)**，彩色图片通常有 3 个通道（红 R、绿 G、蓝 B），每个通道存储对应颜色的像素强度值。

#### 卷积层
这是 CNN 的核心，负责特征的提取。

卷积核 (或者叫滤波器) 是一个小型的矩阵（例如 3x3 或 5x5），它就是 CNN 用于提取特征的“工具”。

卷积核在输入图片的每个小区域上**滑动**（从左到右，从上到下）。在每个位置，卷积核内的值与图片该区域的像素值进行**点乘**（相乘后求和）。这个点乘结果成为输出特征图的一个像素值。

不同的卷积核被训练来提取不同的特征。例如，一个卷积核可能专门提取**垂直边缘**，另一个提取**水平边缘**，还有的提取**纹理**、**角点**等。

经过一次卷积操作后，输出的是一张**特征图 (Feature Map)**，它显示了原图中哪些位置包含该卷积核所提取的特征。
#### 激活函数
在卷积操作之后，通常会使用一个激活函数，最常用的是 **ReLU**（Rectified Linear Unit）。

`f(x) = max(0, x)`。它简单地将所有负值设置为零，正值保持不变。目的是为网络引入**非线性**。如果没有非线性，无论网络有多少层，它都只能学习线性关系，无法处理图像中复杂的模式。
#### 池化层
池化层的作用是**降采样 (Downsampling)**，即减小特征图的尺寸，从而达到以下目的：

* **降低计算量：** 减小了后续层需要处理的数据量。
* **特征不变性：** 使模型对输入图片的小幅平移、旋转或缩放具有一定的**鲁棒性**（不那么敏感）。
* **最常用的：**
    * **最大池化 (Max Pooling)：** 在一个小的区域（如 2x2）内，只保留最大的那个值作为该区域的代表。

#### 堆叠与特征层级 (Stacking Layers)
一个典型的 CNN 会将上述**卷积层-激活函数-池化层**的组合堆叠多次：

* **浅层（靠近输入）：** 提取简单的、通用的特征，如边缘、颜色、纹理。
* **深层（靠近输出）：** 提取复杂的、高层的语义特征，例如：
    * 在人脸识别中，深层特征可能是“鼻子”、“眼睛”或“嘴巴”的组合。
    * 在物体识别中，深层特征可能是“轮子”、“翅膀”或“窗口”的组合。

通过这种层级结构，模型逐渐从像素级别的细节，抽象出图片的高层概念。
#### 全连接层 和 分类
在深层特征提取完毕后，特征图会被“展平”成一个长长的**特征向量**，然后输入到全连接层（也叫密集层）。

* **全连接层：** 这一层的每个神经元都与前一层的所有神经元相连，负责将提取到的高层特征组合起来，进行最终的**决策**。
* **输出层：** 最后一层通常使用 **Softmax** 激活函数。它会将最终的输出转换为一个**概率分布**，即图片属于每个类别的概率。
    * 例如，如果模型判断图片是“猫”的概率是 95%，“狗”的概率是 4%，“鸟”的概率是 1%，那么最终的识别结果就是“猫”。

#### 总结流程图
图片识别的整个过程就是：

$$\text{原始图片} \rightarrow \text{卷积层（提取特征）} \rightarrow \text{池化层（降维/不变性）} \rightarrow \dots \rightarrow \text{全连接层} \rightarrow \text{Softmax} \rightarrow \text{识别结果（概率）}$$

通过**反向传播**和**优化器**，网络在训练过程中不断调整卷积核中的权重和偏差，直到这些卷积核能够最有效地提取出有助于正确识别物体的特征。

## 音频数据
